---
title: "Evaluating LLMs' Assessment of Mixed-Context Hallucination Through the Lens of Summarization"
collection: publications
category: manuscripts
permalink: /publication/2025-03-01-evaluating-llms-assessment-mixed-context-hallucination
excerpt: 'Evaluation of LLMs assessment capabilities for mixed-context hallucination in summarization tasks.'
date: 2025-03-01
venue: 'arXiv preprint'
paperurl: 'https://arxiv.org/abs/2503.01670'
citation: 'S Qi, R Cao, Y He, Z Yuan. (2025). &quot;Evaluating LLMs Assessment of Mixed-Context Hallucination Through the Lens of Summarization.&quot; <i>arXiv preprint arXiv:2503.01670</i>.'
---

This paper evaluates large language models' ability to assess mixed-context hallucination through summarization tasks. We analyze how LLMs perform in detecting and evaluating hallucination when presented with mixed or conflicting information contexts.

The research contributes to understanding LLMs' self-assessment capabilities and their limitations in detecting their own hallucination patterns. 